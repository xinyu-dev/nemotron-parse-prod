{
    "source_document": "output_results/resized_images/pasa_page_3_fitz_resized.png",
    "source_page_number": 0,
    "processing_timestamp_utc": "2025-11-17T21:37:10.066957+00:00",
    "status": "Layout extraction successful (Docker Inference)",
    "content": [
        {
            "extraction_id": 0,
            "metadata": {
                "source_page": 0,
                "type": "Text",
                "bbox": {
                    "xmin": 0.16419963570127505,
                    "ymin": 0.0883,
                    "xmax": 0.4895970856102004,
                    "ymax": 0.1133
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "<tbc>The main contributions of this paper are summarized as follows:"
            }
        },
        {
            "extraction_id": 1,
            "metadata": {
                "source_page": 0,
                "type": "List-item",
                "bbox": {
                    "xmin": 0.1837114754098361,
                    "ymin": 0.1313,
                    "xmax": 0.4895970856102004,
                    "ymax": 0.1914
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "\u2022 We introduce PaSa, a comprehensive and accurate paper search agent that can autonomously use online search tools, read entire papers, and navigate citation networks.<tbc>"
            }
        },
        {
            "extraction_id": 2,
            "metadata": {
                "source_page": 0,
                "type": "List-item",
                "bbox": {
                    "xmin": 0.1837114754098361,
                    "ymin": 0.207,
                    "xmax": 0.4895970856102004,
                    "ymax": 0.2508
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "\u2022 We develop two high-quality datasets for complex academic search, AutoScholarQuery and RealScholarQuery.<tbc>"
            }
        },
        {
            "extraction_id": 3,
            "metadata": {
                "source_page": 0,
                "type": "List-item",
                "bbox": {
                    "xmin": 0.1837114754098361,
                    "ymin": 0.2664,
                    "xmax": 0.4895970856102004,
                    "ymax": 0.3578
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "\u2022 Although PaSa is trained solely on synthetic data, it achieves remarkable real-world performance. Experiments demonstrate that PaSa, built on 7B LLM, significantly outperforms all baselines, including GPT-4 agent, Google- based search, and chatGPT."
            }
        },
        {
            "extraction_id": 4,
            "metadata": {
                "source_page": 0,
                "type": "Section-header",
                "bbox": {
                    "xmin": 0.16419963570127505,
                    "ymin": 0.3742,
                    "xmax": 0.2960796599878567,
                    "ymax": 0.3844
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "## 2 Related Work"
            }
        },
        {
            "extraction_id": 5,
            "metadata": {
                "source_page": 0,
                "type": "Section-header",
                "bbox": {
                    "xmin": 0.16419963570127505,
                    "ymin": 0.4008,
                    "xmax": 0.3625199757134184,
                    "ymax": 0.4125
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "### LLMs in Scientific Discovery"
            }
        },
        {
            "extraction_id": 6,
            "metadata": {
                "source_page": 0,
                "type": "Text",
                "bbox": {
                    "xmin": 0.16419963570127505,
                    "ymin": 0.4008,
                    "xmax": 0.4895970856102004,
                    "ymax": 0.718
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "LLMs have been applied across various stages of scientific discovery (Van Noorden and Perkel, 2023; Lu et al., 2024; Messeri and Crockett, 2024; Liao et al., 2024), such as brainstorming ideas (Girotra et al., 2023; Wang et al., 2024a; Baek et al., 2024), designing experiments (M. Bran et al., 2024), writing code (Xu et al., 2022), and generating research papers (Shao et al., 2024; Agarwal et al., 2024; Wang et al., 2024b). One of the most fundamental yet critical stages in research is conducting academic surveys. Despite its importance, current tools like Google Scholar are often insufficient, leading researchers to spend considerable time on literature review tasks (Kingsley et al., 2011; Gusenbauer and Haddaway, 2021, 2020). This challenge motivates us to develop PaSa, an LLM agent designed to autonomously and comprehensively assist researchers in collecting relevant research papers for complex scholarly queries."
            }
        },
        {
            "extraction_id": 7,
            "metadata": {
                "source_page": 0,
                "type": "Section-header",
                "bbox": {
                    "xmin": 0.16419963570127505,
                    "ymin": 0.7312,
                    "xmax": 0.2521530054644809,
                    "ymax": 0.743
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "### LLM Agents"
            }
        },
        {
            "extraction_id": 8,
            "metadata": {
                "source_page": 0,
                "type": "Text",
                "bbox": {
                    "xmin": 0.16419963570127505,
                    "ymin": 0.7312,
                    "xmax": 0.4895970856102004,
                    "ymax": 0.9203
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "LLM Agents combine LLMs with memory, tool use, and planning, enabling them to perform more complex tasks such as personal copilots (Stratton, 2024), travel planning (Gundawar et al., 2024), web operations (Deng et al., 2024), software development (Qian et al., 2023), and scientific experimentation (Bran et al., 2023). In addition to realizing LLM Agents through prompt engineering (Park et al., 2023; Yao et al., 2023; Shinn et al., 2024; Chen et al., 2023), recent research has focused on optimizing and training these agents (Feng et al., 2024; Putta et al., 2024; Liu<tbc>"
            }
        },
        {
            "extraction_id": 9,
            "metadata": {
                "source_page": 0,
                "type": "Text",
                "bbox": {
                    "xmin": 0.5110100789313905,
                    "ymin": 0.0883,
                    "xmax": 0.8364075288403158,
                    "ymax": 0.2289
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "<tbc>et al., 2023). Among these efforts, AGILE (Feng et al., 2024), a reinforcement learning framework for LLM agents, allows the joint optimization of all agent skills in an end-to-end manner. In our work, we adopt the AGILE framework to implement PaSa. Specifically, we design a novel session-level PPO algorithm to address the unique challenges of the paper search task, including sparse rewards and long trajectories."
            }
        },
        {
            "extraction_id": 10,
            "metadata": {
                "source_page": 0,
                "type": "Section-header",
                "bbox": {
                    "xmin": 0.512010686095932,
                    "ymin": 0.2437,
                    "xmax": 0.601965270188221,
                    "ymax": 0.2539
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "## 3 Datasets"
            }
        },
        {
            "extraction_id": 11,
            "metadata": {
                "source_page": 0,
                "type": "Section-header",
                "bbox": {
                    "xmin": 0.512010686095932,
                    "ymin": 0.2695,
                    "xmax": 0.6781114754098361,
                    "ymax": 0.2812
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "### 3.1 AutoScholarQuery"
            }
        },
        {
            "extraction_id": 12,
            "metadata": {
                "source_page": 0,
                "type": "Text",
                "bbox": {
                    "xmin": 0.5110100789313905,
                    "ymin": 0.2906,
                    "xmax": 0.8364075288403158,
                    "ymax": 0.3344
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "AutoScholarQuery is a synthetic but high-quality dataset of academic queries and related papers, specifically curated for the AI field."
            }
        },
        {
            "extraction_id": 13,
            "metadata": {
                "source_page": 0,
                "type": "Text",
                "bbox": {
                    "xmin": 0.5110100789313905,
                    "ymin": 0.3391,
                    "xmax": 0.8364075288403158,
                    "ymax": 0.5758
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "To construct AutoScholarQuery, we began by collecting all papers published at ICLR 2023, ICML 2023, NeurIPS 2023, ACL 2024, and CVPR 2024. For the Related Work section of each paper, we prompted GPT-4o (Hurst et al., 2024) to generate scholarly queries, where the answers to these queries correspond to the references cited in the Related Work section. The prompt used is shown in Appendix E.1. For each query, we retained only the papers that could be retrieved on arXiv<sup>6</sup>, using their `arxiv\\_id` as the unique article identifier in the dataset. We adopt the publication date of the source paper as the query date. During both training and testing, we only considered papers published prior to the query date."
            }
        },
        {
            "extraction_id": 14,
            "metadata": {
                "source_page": 0,
                "type": "Text",
                "bbox": {
                    "xmin": 0.5110100789313905,
                    "ymin": 0.5805,
                    "xmax": 0.8364075288403158,
                    "ymax": 0.718
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "The final AutoScholarQuery dataset comprises 33,551, 1,000, and 1,000 instances in the training, development, and testing splits, respectively. Each instance consists of a query, the associated paper set, and the query date, with queries in each split derived from distinct source papers.  1 provides illustrative examples from AutoScholarQuery, while additional dataset statistics are summarized in  2."
            }
        },
        {
            "extraction_id": 15,
            "metadata": {
                "source_page": 0,
                "type": "Text",
                "bbox": {
                    "xmin": 0.5110100789313905,
                    "ymin": 0.725,
                    "xmax": 0.8364075288403158,
                    "ymax": 0.8977
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "To evaluate the quality of AutoScholarQuery, we sampled 100 query-paper pairs and assessed the rationality and relevance of each query and the corresponding paper. A qualified query should be meaningful and unambiguous. A qualified paper should match the requirements of the scholarly query. The author manually reviewed each pair, determining that 94.0% of the queries were qualified. Among these qualified queries, 93.7% had corresponding papers that were deemed relevant and appropriate."
            }
        },
        {
            "extraction_id": 16,
            "metadata": {
                "source_page": 0,
                "type": "Footnote",
                "bbox": {
                    "xmin": 0.5306219793564055,
                    "ymin": 0.9086,
                    "xmax": 0.6546972677595628,
                    "ymax": 0.9195
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "<sup>6</sup>`https://arxiv.org/`"
            }
        },
        {
            "extraction_id": 17,
            "metadata": {
                "source_page": 0,
                "type": "Page-footer",
                "bbox": {
                    "xmin": 0.4954006071645416,
                    "ymin": 0.9445,
                    "xmax": 0.503205343047966,
                    "ymax": 0.9531
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "3"
            }
        }
    ]
}