{
    "source_document": "output_results/resized_images/pasa_page_8_fitz_resized.png",
    "source_page_number": 0,
    "processing_timestamp_utc": "2025-11-17T21:37:27.707750+00:00",
    "status": "Layout extraction successful (Docker Inference)",
    "content": [
        {
            "extraction_id": 0,
            "metadata": {
                "source_page": 0,
                "type": "List-item",
                "bbox": {
                    "xmin": 0.19641918639951428,
                    "ymin": 0.4648,
                    "xmax": 0.4895970856102004,
                    "ymax": 0.4922
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "sion, we evaluate only 100 randomly sampled instances from the AutoScholarQuery test set.<tbc>"
            }
        },
        {
            "extraction_id": 1,
            "metadata": {
                "source_page": 0,
                "type": "List-item",
                "bbox": {
                    "xmin": 0.1837114754098361,
                    "ymin": 0.5062,
                    "xmax": 0.4865952641165756,
                    "ymax": 0.5344
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "\u2022 **GPT-o1.** Prompt GPT-o1 to process the scholar query.<tbc>"
            }
        },
        {
            "extraction_id": 2,
            "metadata": {
                "source_page": 0,
                "type": "List-item",
                "bbox": {
                    "xmin": 0.1837114754098361,
                    "ymin": 0.5477,
                    "xmax": 0.4875958712811172,
                    "ymax": 0.6078
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "\u2022 **PaSa-GPT-4o.** Prompt GPT-4o within the PaSa framework. It can perform multiple searches, paper reading, and citation network crawling."
            }
        },
        {
            "extraction_id": 3,
            "metadata": {
                "source_page": 0,
                "type": "Text",
                "bbox": {
                    "xmin": 0.16419963570127505,
                    "ymin": 0.6203,
                    "xmax": 0.4865952641165756,
                    "ymax": 0.6484
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "We carefully designed prompts for all baselines and they are shown in Appendix E.1."
            }
        },
        {
            "extraction_id": 4,
            "metadata": {
                "source_page": 0,
                "type": "Text",
                "bbox": {
                    "xmin": 0.16419963570127505,
                    "ymin": 0.6531,
                    "xmax": 0.4895970856102004,
                    "ymax": 0.7422
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "As shown in Figure 2, the crawling process of PaSa can be visualized as a paper tree. In practice, considering the computational expense, we limit the Crawler\u2019s exploration depth (starting from the user query) to three for both PaSa-7b and PaSa- GPT-4o."
            }
        },
        {
            "extraction_id": 5,
            "metadata": {
                "source_page": 0,
                "type": "Text",
                "bbox": {
                    "xmin": 0.16419963570127505,
                    "ymin": 0.7492,
                    "xmax": 0.4895970856102004,
                    "ymax": 0.8547
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "For Google-based baselines, we evaluate recall using Recall@20, Recall@50, and Recall@100 metrics for the top-20, top-50, and top-100 search results, respectively. For other baselines, we assess precision and recall for the final retrieved papers. Additionally, we compare the crawler\u2019s recall between PaSa-GPT-4o and PaSa-7b."
            }
        },
        {
            "extraction_id": 6,
            "metadata": {
                "source_page": 0,
                "type": "Section-header",
                "bbox": {
                    "xmin": 0.16419963570127505,
                    "ymin": 0.8719,
                    "xmax": 0.28627370977534916,
                    "ymax": 0.8812
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "## 5.3 Main results"
            }
        },
        {
            "extraction_id": 7,
            "metadata": {
                "source_page": 0,
                "type": "Text",
                "bbox": {
                    "xmin": 0.16419963570127505,
                    "ymin": 0.893,
                    "xmax": 0.4895970856102004,
                    "ymax": 0.9203
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "As shown in  5, PaSa-7b outperforms all baselines on AutoScholarQuery test set. Specifically,<tbc>"
            }
        },
        {
            "extraction_id": 8,
            "metadata": {
                "source_page": 0,
                "type": "Text",
                "bbox": {
                    "xmin": 0.5110100789313905,
                    "ymin": 0.4648,
                    "xmax": 0.8364075288403158,
                    "ymax": 0.6047
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "<tbc>compared to the strongest baseline, PaSa-GPT-4o, PaSa-7b demonstrates a 9.64% improvement in recall with comparable precision. Moreover, the recall of the Crawler in PaSa-7b is 3.66% higher than that in PaSa-GPT-4o. When compared to the best Google-based baseline, Google with GPT-4o, PaSa- 7b achieves an improvement of 33.80%, 38.83% and 42.64% in Recall@20, Recall@50 and Recall@100, respectively."
            }
        },
        {
            "extraction_id": 9,
            "metadata": {
                "source_page": 0,
                "type": "Text",
                "bbox": {
                    "xmin": 0.5110100789313905,
                    "ymin": 0.6141,
                    "xmax": 0.8364075288403158,
                    "ymax": 0.7063
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "We observe that using multiple ensembles of Crawler during inference can improve performance. Specifically, running Crawler twice during inference increased the Crawler recall by 3.34% on AutoScholarQuery, leading to the final recall improvement by 1.51%, with precision remaining similar."
            }
        },
        {
            "extraction_id": 10,
            "metadata": {
                "source_page": 0,
                "type": "Text",
                "bbox": {
                    "xmin": 0.5110100789313905,
                    "ymin": 0.7156,
                    "xmax": 0.8364075288403158,
                    "ymax": 0.9203
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "To evaluate PaSa in a more realistic setting, we assess its effectiveness on RealScholarQuery. As illustrated in  6, PaSa-7b exhibits a greater advantage in real-world academic search scenarios. Compared to PaSa-GPT-4o, PaSa-7b achieves improvements of 30.36% in recall and 4.25% in precision. Against the best Google-based baseline on RealScholarQuery, Google with GPT-4o, PaSa- 7b outperforms Google by 37.78%, 39.90%, and 39.83% in recall@20, recall@50 and recall@100, respectively. Additionally, the PaSa-7b-ensemble further enhances crawler recall by 4.32%, contributing to an overall 3.52% improvement in the recall<tbc>"
            }
        },
        {
            "extraction_id": 11,
            "metadata": {
                "source_page": 0,
                "type": "Page-footer",
                "bbox": {
                    "xmin": 0.4954006071645416,
                    "ymin": 0.9445,
                    "xmax": 0.503205343047966,
                    "ymax": 0.9531
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "8"
            }
        },
        {
            "extraction_id": 12,
            "metadata": {
                "source_page": 0,
                "type": "Table",
                "bbox": {
                    "xmin": 0.18471208257437766,
                    "ymin": 0.0891,
                    "xmax": 0.8139939283545841,
                    "ymax": 0.2297
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "tabular",
                "content_html": "<table>\n  <tr>\n    <td><b>Method</b></td>\n    <td><b>Crawler Recall</b></td>\n    <td><b>Precision</b></td>\n    <td><b>Recall</b></td>\n    <td><b>Recall@100</b></td>\n    <td><b>Recall@50</b></td>\n    <td><b>Recall@20</b></td>\n  </tr>\n  <tr>\n    <td>Google</td>\n    <td>-</td>\n    <td>-</td>\n    <td>-</td>\n    <td>0.2015</td>\n    <td>0.1891</td>\n    <td>0.1568</td>\n  </tr>\n  <tr>\n    <td>Google Scholar</td>\n    <td>-</td>\n    <td>-</td>\n    <td>-</td>\n    <td>0.1130</td>\n    <td>0.0970</td>\n    <td>0.0609</td>\n  </tr>\n  <tr>\n    <td>Google with GPT-4o</td>\n    <td>-</td>\n    <td>-</td>\n    <td>-</td>\n    <td>0.2683</td>\n    <td>0.2450</td>\n    <td>0.1921</td>\n  </tr>\n  <tr>\n    <td>ChatGPT</td>\n    <td>-</td>\n    <td>0.0507</td>\n    <td>0.3046</td>\n    <td>-</td>\n    <td>-</td>\n    <td>-</td>\n  </tr>\n  <tr>\n    <td>GPT-o1</td>\n    <td>-</td>\n    <td>0.0413</td>\n    <td>0.1925</td>\n    <td>-</td>\n    <td>-</td>\n    <td>-</td>\n  </tr>\n  <tr>\n    <td>PaSa-GPT-4o</td>\n    <td>0.7565</td>\n    <td>0.1457</td>\n    <td>0.3873</td>\n    <td>-</td>\n    <td>-</td>\n    <td>-</td>\n  </tr>\n  <tr>\n    <td>PaSa-7b</td>\n    <td>0.7931</td>\n    <td>0.1448</td>\n    <td>0.4834</td>\n    <td>0.6947</td>\n    <td>0.6334</td>\n    <td>0.5301</td>\n  </tr>\n  <tr>\n    <td>PaSa-7b-ensemble</td>\n    <td>0.8265</td>\n    <td>0.1410</td>\n    <td>0.4985</td>\n    <td>0.7099</td>\n    <td>0.6386</td>\n    <td>0.5326</td>\n  </tr>\n</table>"
            }
        },
        {
            "extraction_id": 13,
            "metadata": {
                "source_page": 0,
                "type": "Table",
                "bbox": {
                    "xmin": 0.18471208257437766,
                    "ymin": 0.2727,
                    "xmax": 0.8139939283545841,
                    "ymax": 0.4141
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "tabular",
                "content_html": "<table>\n  <tr>\n    <td><b>Method</b></td>\n    <td><b>Crawler Recall</b></td>\n    <td><b>Precision</b></td>\n    <td><b>Recall</b></td>\n    <td><b>Recall@100</b></td>\n    <td><b>Recall@50</b></td>\n    <td><b>Recall@20</b></td>\n  </tr>\n  <tr>\n    <td>Google</td>\n    <td>-</td>\n    <td>-</td>\n    <td>-</td>\n    <td>0.2535</td>\n    <td>0.2342</td>\n    <td>0.1834</td>\n  </tr>\n  <tr>\n    <td>Google Scholar</td>\n    <td>-</td>\n    <td>-</td>\n    <td>-</td>\n    <td>0.2809</td>\n    <td>0.2155</td>\n    <td>0.1514</td>\n  </tr>\n  <tr>\n    <td>Google with GPT-4o</td>\n    <td>-</td>\n    <td>-</td>\n    <td>-</td>\n    <td>0.2946</td>\n    <td>0.2573</td>\n    <td>0.2020</td>\n  </tr>\n  <tr>\n    <td>ChatGPT</td>\n    <td>-</td>\n    <td>0.2280</td>\n    <td>0.2007</td>\n    <td>-</td>\n    <td>-</td>\n    <td>-</td>\n  </tr>\n  <tr>\n    <td>GPT-o1</td>\n    <td>-</td>\n    <td>0.058</td>\n    <td>0.0134</td>\n    <td>-</td>\n    <td>-</td>\n    <td>-</td>\n  </tr>\n  <tr>\n    <td>PaSa-GPT-4o</td>\n    <td>0.5494</td>\n    <td>0.4721</td>\n    <td>0.3075</td>\n    <td>-</td>\n    <td>-</td>\n    <td>-</td>\n  </tr>\n  <tr>\n    <td>PaSa-7b</td>\n    <td>0.7071</td>\n    <td>0.5146</td>\n    <td>0.6111</td>\n    <td>0.6929</td>\n    <td>0.6563</td>\n    <td>0.5798</td>\n  </tr>\n  <tr>\n    <td>PaSa-7b-ensemble</td>\n    <td>0.7503</td>\n    <td>0.4938</td>\n    <td>0.6488</td>\n    <td>0.7281</td>\n    <td>0.6877</td>\n    <td>0.5986</td>\n  </tr>\n</table>"
            }
        },
        {
            "extraction_id": 14,
            "metadata": {
                "source_page": 0,
                "type": "Caption",
                "bbox": {
                    "xmin": 0.3606188221007893,
                    "ymin": 0.2477,
                    "xmax": 0.6370865816636309,
                    "ymax": 0.2578
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "5: Results on AutoScholarQuery test set."
            }
        },
        {
            "extraction_id": 15,
            "metadata": {
                "source_page": 0,
                "type": "Caption",
                "bbox": {
                    "xmin": 0.3840330297510625,
                    "ymin": 0.4313,
                    "xmax": 0.6136723740133576,
                    "ymax": 0.4414
                }
            },
            "confidence": "N/A",
            "extraction_status": "Success",
            "data": {
                "type": "textual",
                "content": "6: Results on RealScholarQuery."
            }
        }
    ]
}